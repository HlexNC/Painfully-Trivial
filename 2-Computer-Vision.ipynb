{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O9BGeOMMMN3"
      },
      "source": [
        "## **Computer vision project: Deggendorf Waste Sorting Assistant**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnYmouOpMMN4"
      },
      "source": [
        "### **Overview**\n",
        "The Deggendorf Waste Sorting Assistant is a Computer Vision-based tool designed to help residents and international students correctly identify waste bins. The project leverages image classification to determine the category of a given waste bin based on its visual characteristics. Users can take a picture of an unlabeled bin, and the model will classify it while providing information on the appropriate waste materials for disposal.\n",
        "\n",
        "### **Project Goals**\n",
        "- Develop an image classification model capable of identifying waste bins in Deggendorf.\n",
        "- Provide users with clear guidance on proper waste disposal based on bin classification.\n",
        "- Document all processes in a Jupyter Notebook, covering dataset creation, model training, evaluation, and deployment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdX4RKxKDUzw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8hC-qkbDUzw"
      },
      "source": [
        "## **1. Environment Setup & Dependencies**\n",
        "\n",
        "```bash\n",
        "# Using conda\n",
        "conda create -n waste-detection python=3.10\n",
        "conda activate waste-detection\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFGm3NfSMMN4",
        "outputId": "a38a21c5-8f2b-483f-dedc-5784c9536b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Running NumPy compatibility check...\n",
            "‚úÖ NumPy 1.26.4 working correctly\n",
            "\n",
            "üì¶ Installing dependencies...\n",
            "Installing pillow>=10.0.0...\n",
            "‚úÖ opencv-python already installed\n",
            "‚úÖ matplotlib already installed\n",
            "‚úÖ pandas already installed\n",
            "‚úÖ seaborn already installed\n",
            "Installing pyyaml>=6.0...\n",
            "‚úÖ tqdm already installed\n",
            "‚úÖ shutil already installed\n",
            "‚úÖ ultralytics already installed\n",
            "\n",
            "Installing Label Studio packages (optional)...\n",
            "‚úÖ label-studio already installed\n",
            "‚úÖ label-studio-converter already installed\n",
            "\n",
            "üîç Final verification...\n",
            "‚úÖ numpy\n",
            "‚úÖ cv2\n",
            "‚úÖ PIL\n",
            "‚úÖ matplotlib\n",
            "‚úÖ pandas\n",
            "‚úÖ yaml\n",
            "‚úÖ ultralytics\n",
            "‚úÖ shutil\n",
            "\n",
            "üéâ All dependencies installed and verified successfully!\n",
            "\n",
            "üí° If you see 'numpy.dtype size changed' errors, restart the runtime and run this cell again.\n"
          ]
        }
      ],
      "source": [
        "# 1.0 ¬∑ Check environment and install dependencies (FIXED with QuickFix)\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "\n",
        "def is_colab():\n",
        "    \"\"\"Check if running in Google Colab\"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
        "\n",
        "def reinstall_package(package):\n",
        "    \"\"\"Reinstall a package (force reinstall)\"\"\"\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"--force-reinstall\", package])\n",
        "\n",
        "# QUICKFIX: Check for NumPy binary compatibility issues\n",
        "print(\"üîß Running NumPy compatibility check...\")\n",
        "numpy_needs_fix = False\n",
        "try:\n",
        "    import numpy\n",
        "    # Test numpy functionality - this is where the error typically occurs\n",
        "    test_array = numpy.array([1, 2, 3])\n",
        "    numpy.random.RandomState(42)  # This often triggers the binary incompatibility error\n",
        "    print(f\"‚úÖ NumPy {numpy.__version__} working correctly\")\n",
        "except (ImportError, ValueError) as e:\n",
        "    print(f\"‚ùå NumPy binary compatibility issue detected: {e}\")\n",
        "    numpy_needs_fix = True\n",
        "\n",
        "if numpy_needs_fix:\n",
        "    print(\"üîß Applying NumPy QuickFix...\")\n",
        "    # Force reinstall numpy and related packages\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"--no-deps\", \"--quiet\", \"numpy>=1.23.0\"])\n",
        "    print(\"‚úÖ NumPy reinstalled - you may need to restart runtime\")\n",
        "\n",
        "    # Test again after reinstall\n",
        "    try:\n",
        "        import numpy\n",
        "        test_array = numpy.array([1, 2, 3])\n",
        "        print(\"‚úÖ NumPy QuickFix successful\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è NumPy still has issues: {e}\")\n",
        "        print(\"üí° Please restart the runtime and run this cell again\")\n",
        "\n",
        "print(\"\\nüì¶ Installing dependencies...\")\n",
        "\n",
        "# Core dependencies in installation order\n",
        "core_packages = [\n",
        "    \"pillow>=10.0.0\",\n",
        "    \"opencv-python>=4.6.0\",\n",
        "    \"matplotlib>=3.5.0\",\n",
        "    \"pandas>=2.0.0\",\n",
        "    \"seaborn>=0.12.0\",\n",
        "    \"pyyaml>=6.0\",\n",
        "    \"tqdm>=4.64.0\",\n",
        "    \"shutil\"\n",
        "]\n",
        "\n",
        "# Install core packages\n",
        "for pkg in core_packages:\n",
        "    try:\n",
        "        module_name = pkg.split('>=')[0].replace('-', '_')\n",
        "        if module_name == 'opencv_python':\n",
        "            module_name = 'cv2'\n",
        "        importlib.import_module(module_name)\n",
        "        print(f\"‚úÖ {pkg.split('>=')[0]} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {pkg}...\")\n",
        "        install_package(pkg)\n",
        "\n",
        "# Install Ultralytics\n",
        "try:\n",
        "    import ultralytics\n",
        "    print(\"‚úÖ ultralytics already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing ultralytics>=8.0.0...\")\n",
        "    install_package(\"ultralytics>=8.0.0\")\n",
        "\n",
        "# Install Label Studio (optional - may fail, that's okay)\n",
        "label_studio_packages = [\n",
        "    \"label-studio>=1.0.0\",\n",
        "    \"label-studio-converter>=0.0.1\",\n",
        "]\n",
        "\n",
        "print(\"\\nInstalling Label Studio packages (optional)...\")\n",
        "for pkg in label_studio_packages:\n",
        "    try:\n",
        "        module_name = pkg.split('>=')[0].replace('-', '_')\n",
        "        importlib.import_module(module_name)\n",
        "        print(f\"‚úÖ {pkg.split('>=')[0]} already installed\")\n",
        "    except ImportError:\n",
        "        try:\n",
        "            print(f\"Installing {pkg}...\")\n",
        "            install_package(pkg)\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"‚ö†Ô∏è Could not install {pkg} - continuing without it\")\n",
        "\n",
        "print(\"\\nüîç Final verification...\")\n",
        "\n",
        "# Verify critical imports\n",
        "critical_imports = {\n",
        "    'numpy': 'numpy',\n",
        "    'cv2': 'opencv-python',\n",
        "    'PIL': 'pillow',\n",
        "    'matplotlib': 'matplotlib',\n",
        "    'pandas': 'pandas',\n",
        "    'yaml': 'pyyaml',\n",
        "    'ultralytics': 'ultralytics',\n",
        "    'shutil': 'shutil'\n",
        "}\n",
        "\n",
        "all_good = True\n",
        "for module, package in critical_imports.items():\n",
        "    try:\n",
        "        importlib.import_module(module)\n",
        "        print(f\"‚úÖ {module}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå {module} failed: {e}\")\n",
        "        all_good = False\n",
        "\n",
        "if all_good:\n",
        "    print(\"\\nüéâ All dependencies installed and verified successfully!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Some packages failed - you may need to restart runtime and try again\")\n",
        "\n",
        "print(\"\\nüí° If you see 'numpy.dtype size changed' errors, restart the runtime and run this cell again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft4JRJwKMMN5",
        "outputId": "54b276b6-a753-4e83-adf1-8ed5ea6e0779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ raw_images: cv_garbage\\raw_images\n",
            "üìÅ labeled_images: cv_garbage\\labeled_images\n",
            "üìÅ yolo_dataset: cv_garbage\\YOLO_Dataset\n",
            "üìÅ models: cv_garbage\\models\n",
            "üìÅ results: cv_garbage\\results\n"
          ]
        }
      ],
      "source": [
        "# 1.1 ¬∑ Mount Google Drive (if in Colab)\n",
        "if is_colab():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    BASE_PATH = Path(\"/content/drive/MyDrive/cv_garbage\")\n",
        "else:\n",
        "    # For local environment, adjust this path\n",
        "    BASE_PATH = Path(\"./cv_garbage\")\n",
        "\n",
        "# Create directory structure\n",
        "DIRS = {\n",
        "    \"raw_images\": BASE_PATH / \"raw_images\",\n",
        "    \"labeled_images\": BASE_PATH / \"labeled_images\",\n",
        "    \"yolo_dataset\": BASE_PATH / \"YOLO_Dataset\",\n",
        "    \"models\": BASE_PATH / \"models\",\n",
        "    \"results\": BASE_PATH / \"results\"\n",
        "}\n",
        "\n",
        "for dir_name, dir_path in DIRS.items():\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"üìÅ {dir_name}: {dir_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZh9gzikDUzx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkvPXxQ8DUzx"
      },
      "source": [
        "## **2. Data Annotation Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psFV2vAxDUzx"
      },
      "source": [
        "### **2.1 Check Existing Annotations**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Fsbci9DUzx",
        "outputId": "d3f3a576-b754-4c0a-fdbb-8d6b367d6222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ images/train: 249 files\n",
            "‚úÖ images/val: 94 files\n",
            "‚úÖ labels/train: 372 files\n",
            "‚úÖ labels/val: 94 files\n",
            "‚úÖ Found data.yaml with 4 classes\n",
            "\n",
            "‚úÖ YOLO dataset is ready!\n"
          ]
        }
      ],
      "source": [
        "# 2.1 ¬∑ Check if YOLO annotations already exist\n",
        "import json\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "\n",
        "def check_yolo_dataset():\n",
        "    \"\"\"Check if YOLO dataset structure exists and is valid\"\"\"\n",
        "    yolo_path = DIRS[\"yolo_dataset\"]\n",
        "    required_structure = {\n",
        "        \"images/train\": 0,\n",
        "        \"images/val\": 0,\n",
        "        \"labels/train\": 0,\n",
        "        \"labels/val\": 0,\n",
        "        \"data.yaml\": None\n",
        "    }\n",
        "\n",
        "    dataset_valid = True\n",
        "\n",
        "    for rel_path in required_structure.keys():\n",
        "        full_path = yolo_path / rel_path\n",
        "        if \"data.yaml\" in rel_path:\n",
        "            if not full_path.exists():\n",
        "                print(f\"‚ùå Missing: {rel_path}\")\n",
        "                dataset_valid = False\n",
        "            else:\n",
        "                with open(full_path, 'r') as f:\n",
        "                    data_config = yaml.safe_load(f)\n",
        "                print(f\"‚úÖ Found data.yaml with {data_config.get('nc', 0)} classes\")\n",
        "        else:\n",
        "            if full_path.exists():\n",
        "                if full_path.is_dir():\n",
        "                    count = len(list(full_path.glob(\"*\")))\n",
        "                    required_structure[rel_path] = count\n",
        "                    print(f\"‚úÖ {rel_path}: {count} files\")\n",
        "                    if count == 0:\n",
        "                        dataset_valid = False\n",
        "            else:\n",
        "                print(f\"‚ùå Missing: {rel_path}\")\n",
        "                dataset_valid = False\n",
        "\n",
        "    return dataset_valid, required_structure\n",
        "\n",
        "dataset_exists, dataset_info = check_yolo_dataset()\n",
        "print(f\"\\n{'‚úÖ YOLO dataset is ready!' if dataset_exists else '‚ö†Ô∏è  YOLO dataset needs to be created'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
            "CUDA version: 11.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Not detected\")\n",
        "print(\"CUDA version:\", torch.version.cuda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUCJbVX1DUzy"
      },
      "source": [
        "### **2.2 Label Studio Setup (If Needed)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q8UWp_L1DUzy"
      },
      "outputs": [],
      "source": [
        "# 2.2 ¬∑ Setup Label Studio for bounding box annotation\n",
        "if not dataset_exists:\n",
        "    print(\"\\nüè∑Ô∏è  Setting up Label Studio for annotation...\")\n",
        "\n",
        "    # Create Label Studio config\n",
        "    label_config = \"\"\"\n",
        "    <View>\n",
        "      <Image name=\"image\" value=\"$image\"/>\n",
        "      <RectangleLabels name=\"label\" toName=\"image\">\n",
        "        <Label value=\"Biom√ºll\" background=\"#FF6B6B\"/>\n",
        "        <Label value=\"Glas\" background=\"#4ECDC4\"/>\n",
        "        <Label value=\"Papier\" background=\"#45B7D1\"/>\n",
        "        <Label value=\"Restm√ºll\" background=\"#96CEB4\"/>\n",
        "      </RectangleLabels>\n",
        "    </View>\n",
        "    \"\"\"\n",
        "\n",
        "    config_path = BASE_PATH / \"label_studio_config.xml\"\n",
        "    with open(config_path, 'w') as f:\n",
        "        f.write(label_config)\n",
        "\n",
        "    print(\"‚úÖ Label Studio configuration created\")\n",
        "    print(\"\\nüìã Instructions for Label Studio:\")\n",
        "    print(\"1. Run: label-studio start\")\n",
        "    print(\"2. Create a new project\")\n",
        "    print(\"3. Import the configuration from:\", config_path)\n",
        "    print(\"4. Import images from:\", DIRS[\"labeled_images\"])\n",
        "    print(\"5. Annotate with bounding boxes\")\n",
        "    print(\"6. Export annotations as 'YOLO' format\")\n",
        "    print(\"7. Save to:\", DIRS[\"yolo_dataset\"])\n",
        "\n",
        "    # For automated setup (requires Label Studio SDK)\n",
        "    try:\n",
        "        from label_studio_sdk import Client\n",
        "\n",
        "        # Initialize Label Studio client\n",
        "        LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL', 'http://localhost:8080')\n",
        "        API_KEY = os.getenv('LABEL_STUDIO_API_KEY', '')\n",
        "\n",
        "        if API_KEY:\n",
        "            ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
        "\n",
        "            # Create project\n",
        "            project = ls.start_project(\n",
        "                title=\"Deggendorf Waste Bins\",\n",
        "                label_config=label_config\n",
        "            )\n",
        "\n",
        "            # Import images\n",
        "            image_files = list(DIRS[\"labeled_images\"].glob(\"*.jpg\")) + \\\n",
        "                         list(DIRS[\"labeled_images\"].glob(\"*.png\"))\n",
        "\n",
        "            if image_files:\n",
        "                project.import_data([{\"image\": str(f)} for f in image_files])\n",
        "                print(f\"‚úÖ Imported {len(image_files)} images to Label Studio\")\n",
        "                print(f\"üåê Open Label Studio at: {LABEL_STUDIO_URL}\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  No images found in labeled_images directory\")\n",
        "        else:\n",
        "            print(\"\\nüí° Tip: Set LABEL_STUDIO_API_KEY environment variable for automated setup\")\n",
        "    except ImportError:\n",
        "        print(\"\\nüí° Install label-studio-sdk for automated project setup\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lVF0923DUzy"
      },
      "source": [
        "### **2.3 Convert Label Studio to YOLO Format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xe3Ni08uDUzy"
      },
      "outputs": [],
      "source": [
        "# 2.3 ¬∑ Convert Label Studio annotations to YOLO format\n",
        "def convert_ls_to_yolo(ls_export_path, output_path):\n",
        "    \"\"\"Convert Label Studio JSON export to YOLO format\"\"\"\n",
        "    import json\n",
        "    import shutil\n",
        "    from PIL import Image\n",
        "\n",
        "    # Load Label Studio export\n",
        "    with open(ls_export_path, 'r') as f:\n",
        "        ls_data = json.load(f)\n",
        "\n",
        "    # Class mapping\n",
        "    class_map = {\n",
        "        \"Biom√ºll\": 0,\n",
        "        \"Glas\": 1,\n",
        "        \"Papier\": 2,\n",
        "        \"Restm√ºll\": 3\n",
        "    }\n",
        "\n",
        "    # Prepare directories\n",
        "    for split in ['train', 'val']:\n",
        "        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
        "        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Process annotations\n",
        "    total_images = len(ls_data)\n",
        "    train_split = int(0.8 * total_images)\n",
        "\n",
        "    for idx, item in enumerate(ls_data):\n",
        "        # Determine split\n",
        "        split = 'train' if idx < train_split else 'val'\n",
        "\n",
        "        # Get image info\n",
        "        image_path = Path(item['data']['image'])\n",
        "        image_name = image_path.stem\n",
        "\n",
        "        # Copy image\n",
        "        output_image_path = output_path / 'images' / split / f\"{image_name}.jpg\"\n",
        "        if image_path.exists():\n",
        "            shutil.copy2(image_path, output_image_path)\n",
        "\n",
        "            # Get image dimensions\n",
        "            with Image.open(image_path) as img:\n",
        "                img_width, img_height = img.size\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Image not found: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        # Process annotations\n",
        "        yolo_annotations = []\n",
        "\n",
        "        for annotation in item.get('annotations', []):\n",
        "            for result in annotation.get('result', []):\n",
        "                if result['type'] == 'rectanglelabels':\n",
        "                    # Get bounding box\n",
        "                    x = result['value']['x'] / 100.0\n",
        "                    y = result['value']['y'] / 100.0\n",
        "                    w = result['value']['width'] / 100.0\n",
        "                    h = result['value']['height'] / 100.0\n",
        "\n",
        "                    # Convert to YOLO format (center_x, center_y, width, height)\n",
        "                    center_x = x + w / 2\n",
        "                    center_y = y + h / 2\n",
        "\n",
        "                    # Get class\n",
        "                    label = result['value']['rectanglelabels'][0]\n",
        "                    class_id = class_map.get(label, -1)\n",
        "\n",
        "                    if class_id >= 0:\n",
        "                        yolo_annotations.append(f\"{class_id} {center_x} {center_y} {w} {h}\")\n",
        "\n",
        "        # Save annotations\n",
        "        if yolo_annotations:\n",
        "            label_path = output_path / 'labels' / split / f\"{image_name}.txt\"\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "    # Create data.yaml\n",
        "    data_yaml = {\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'nc': len(class_map),\n",
        "        'names': {v: k for k, v in class_map.items()}\n",
        "    }\n",
        "\n",
        "    with open(output_path / 'data.yaml', 'w') as f:\n",
        "        yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "    print(f\"‚úÖ Converted {total_images} images to YOLO format\")\n",
        "    print(f\"   Train: {train_split}, Val: {total_images - train_split}\")\n",
        "\n",
        "# Check if Label Studio export exists\n",
        "ls_export_path = BASE_PATH / \"label_studio_export.json\"\n",
        "if ls_export_path.exists() and not dataset_exists:\n",
        "    print(\"\\nüîÑ Converting Label Studio annotations to YOLO format...\")\n",
        "    convert_ls_to_yolo(ls_export_path, DIRS[\"yolo_dataset\"])\n",
        "    dataset_exists, dataset_info = check_yolo_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFp9dDBIDUzy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8FlUgWnDUzy"
      },
      "source": [
        "## **3. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZXg4ZmbDUzy"
      },
      "source": [
        "### **3.1 Setup Training Configuration**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du_aGykPDUzy",
        "outputId": "f856cec9-6554-4a1d-dcec-3803a399f20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Training Configuration:\n",
            "   Device: 0\n",
            "   Batch size: 4\n",
            "   Epochs: 50\n",
            "   Model: yolov8s.pt\n"
          ]
        }
      ],
      "source": [
        "# 3.1 ¬∑ Configure training parameters\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Training configuration\n",
        "TRAIN_CONFIG = {\n",
        "    \"model\": \"yolov8s.pt\",  # Base model (n, s, m, l, x)\n",
        "    \"data\": str(DIRS[\"yolo_dataset\"] / \"data.yaml\"),\n",
        "    \"epochs\": 50,\n",
        "    \"imgsz\": 960,\n",
        "    \"batch\": 4,\n",
        "    \"patience\": 20,\n",
        "    \"save\": True,\n",
        "    \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
        "    \"workers\": 8 if not is_colab() else 2,\n",
        "    \"project\": str(DIRS[\"models\"]),\n",
        "    \"name\": f\"waste_detector_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "    \"exist_ok\": False,\n",
        "    \"pretrained\": True,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"lr0\": 0.001,\n",
        "    \"lrf\": 0.01,\n",
        "    \"momentum\": 0.937,\n",
        "    \"weight_decay\": 0.0005,\n",
        "    \"warmup_epochs\": 3.0,\n",
        "    \"warmup_momentum\": 0.8,\n",
        "    \"warmup_bias_lr\": 0.1,\n",
        "    \"box\": 7.5,\n",
        "    \"cls\": 0.5,\n",
        "    \"dfl\": 1.5,\n",
        "    \"hsv_h\": 0.015,\n",
        "    \"hsv_s\": 0.7,\n",
        "    \"hsv_v\": 0.4,\n",
        "    \"degrees\": 0.0,\n",
        "    \"translate\": 0.1,\n",
        "    \"scale\": 0.5,\n",
        "    \"shear\": 0.0,\n",
        "    \"perspective\": 0.0,\n",
        "    \"flipud\": 0.0,\n",
        "    \"fliplr\": 0.5,\n",
        "    \"mosaic\": 1.0,\n",
        "    \"mixup\": 0.0,\n",
        "    \"copy_paste\": 0.0,\n",
        "    \"auto_augment\": \"randaugment\",\n",
        "    \"erasing\": 0.0,\n",
        "    \"crop_fraction\": 1.0\n",
        "}\n",
        "\n",
        "print(\"üîß Training Configuration:\")\n",
        "print(f\"   Device: {TRAIN_CONFIG['device']}\")\n",
        "print(f\"   Batch size: {TRAIN_CONFIG['batch']}\")\n",
        "print(f\"   Epochs: {TRAIN_CONFIG['epochs']}\")\n",
        "print(f\"   Model: {TRAIN_CONFIG['model']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa2tij6LDUzy"
      },
      "source": [
        "### **3.2 Train the Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-W-dkvgDUzy",
        "outputId": "b82386f3-7605-42fb-d673-e9630178b408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Starting model training...\n",
            "New https://pypi.org/project/ultralytics/8.3.159 available  Update with 'pip install -U ultralytics'\n",
            "WARNING 'crop_fraction' is deprecated and will be removed in in the future.\n",
            "Ultralytics 8.3.158  Python-3.12.7 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=cv_garbage\\YOLO_Dataset\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.0, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=waste_detector_20250625_172333, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=cv_garbage\\models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=cv_garbage\\models\\waste_detector_20250625_172333, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,137,148 parameters, 11,137,132 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1079.658.4 MB/s, size: 2340.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\labels\\train.cache... 249 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 249/249 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 791.4224.8 MB/s, size: 2538.8 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\labels\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to cv_garbage\\models\\waste_detector_20250625_172333\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 960 train, 960 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mcv_garbage\\models\\waste_detector_20250625_172333\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      2.12G      1.466       2.76      2.105          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:12<00:00,  5.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.602      0.592      0.604      0.249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      2.38G      1.191      1.555      1.868          5        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.65      0.655      0.701      0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50       2.4G      1.193      1.381      1.868          3        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.471      0.685      0.625      0.306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50       2.4G      1.129      1.315      1.817          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.641      0.703      0.724      0.341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      2.43G      1.167      1.244      1.846          3        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.848      0.785      0.874      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      2.43G       1.05      1.137      1.732          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.813      0.854      0.929      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50      2.43G      1.063      1.069      1.732          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.772      0.883      0.915      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      2.44G      1.038      1.074      1.695          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.659      0.858      0.826      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      2.47G      1.052      1.131      1.739          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.833      0.858      0.894      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50      2.47G      1.009      1.101      1.646          5        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.772      0.697       0.87      0.541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50      2.47G      1.037      1.088      1.707          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.824       0.81      0.884      0.499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50       2.5G       1.02      1.073      1.674          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.801      0.914      0.927      0.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50      2.51G      1.012      1.065      1.678          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.85      0.883      0.942      0.617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      2.51G     0.9475      1.023      1.624          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.876      0.773      0.928      0.609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50      2.51G     0.9539     0.9889      1.609          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.804      0.781      0.876      0.562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      2.54G      0.967     0.9369      1.644          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.762      0.869      0.888       0.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50      2.54G     0.9207     0.8575      1.584          3        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.931      0.866      0.943       0.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      2.54G     0.8831     0.8658      1.574          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.888      0.807      0.926       0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50      2.58G      0.948     0.9245       1.62          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.804      0.929       0.94      0.602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      2.58G      0.848     0.7915      1.535          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.907      0.887      0.948      0.642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50      2.58G      0.909     0.8301      1.608          3        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.94      0.896      0.955      0.654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      2.58G     0.8416     0.7976      1.541          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.854      0.885      0.943      0.637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50      2.58G     0.8247     0.7916      1.513          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.87      0.878      0.938       0.56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50      2.58G     0.8666     0.8275      1.546          3        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.826      0.923      0.915      0.594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50      2.58G     0.8696     0.8187       1.58          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.894      0.872      0.955      0.666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50      2.58G     0.8365     0.7847      1.535          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.88      0.881      0.957      0.658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50      2.58G     0.8126      0.759      1.506          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  8.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.85      0.914      0.948      0.672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50      2.58G     0.8219     0.7431      1.498          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.812      0.953      0.951      0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50      2.58G     0.8036     0.7409      1.495          5        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.94      0.813      0.944       0.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50      2.58G      0.851     0.7862       1.53          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.959      0.827      0.947      0.677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50      2.58G     0.8325     0.7477      1.532          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.939      0.907      0.977      0.687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50      2.58G     0.8301     0.7643      1.512          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.925      0.913      0.975       0.69\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      33/50      2.58G     0.7329     0.6787      1.436          3        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.92      0.925      0.978      0.682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      34/50      2.58G     0.7538     0.6563      1.451          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.919      0.944      0.975      0.691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      35/50      2.58G     0.7652      0.663      1.469          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.902      0.871      0.954      0.645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      36/50      2.58G     0.7917     0.7227      1.458          2        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.912      0.931      0.977      0.702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      37/50      2.58G     0.7624     0.6642      1.441          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.955      0.918      0.986      0.717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      38/50      2.58G     0.7483      0.632      1.437          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.94      0.916       0.98      0.703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      39/50      2.58G     0.6962     0.5937      1.394          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.945      0.927      0.979       0.72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      40/50      2.58G     0.7379     0.6161      1.451          4        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.926      0.925      0.974      0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      41/50      2.58G     0.8884      0.613      1.495          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.901      0.913      0.968      0.684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      42/50      2.58G     0.9317     0.6597      1.483          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.968      0.927      0.979      0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      43/50      2.58G      0.895     0.6726      1.512          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.963       0.92       0.98      0.737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      44/50      2.58G     0.7794     0.5545      1.484          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.972      0.895      0.982       0.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      45/50      2.58G     0.7696     0.5625      1.509          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105       0.98      0.909      0.987       0.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      46/50      2.58G     0.7839     0.5776      1.509          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.977      0.922      0.986      0.752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      47/50      2.58G     0.7414     0.5757      1.423          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.978      0.931      0.986      0.755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      48/50      2.58G     0.7281      0.517      1.417          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.966      0.938      0.986      0.752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      49/50      2.58G     0.6843     0.5165      1.386          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.966      0.938      0.987      0.756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      50/50      2.58G     0.7135     0.4987      1.445          1        960: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:09<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.942      0.949      0.987      0.759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "50 epochs completed in 0.164 hours.\n",
            "Optimizer stripped from cv_garbage\\models\\waste_detector_20250625_172333\\weights\\last.pt, 22.6MB\n",
            "Optimizer stripped from cv_garbage\\models\\waste_detector_20250625_172333\\weights\\best.pt, 22.6MB\n",
            "\n",
            "Validating cv_garbage\\models\\waste_detector_20250625_172333\\weights\\best.pt...\n",
            "Ultralytics 8.3.158  Python-3.12.7 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
            "Model summary (fused): 72 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.948      0.947      0.987      0.759\n",
            "               Biomll         21         24      0.953          1      0.992      0.713\n",
            "                  Glas         12         12      0.955          1      0.995      0.824\n",
            "                Papier         26         27      0.959       0.86       0.98      0.717\n",
            "              Restmll         40         42      0.925      0.929      0.979      0.782\n",
            "Speed: 1.6ms preprocess, 9.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mcv_garbage\\models\\waste_detector_20250625_172333\u001b[0m\n",
            "\n",
            "‚úÖ Training completed!\n",
            "   Best model saved at: cv_garbage\\models\\waste_detector_20250625_172333\\weights\\best.pt\n",
            "   Copied to: cv_garbage\\models\\waste_detector_best.pt\n",
            "\n",
            "üìä Training Results:\n",
            "   mAP50: 0.987\n",
            "   mAP50-95: 0.759\n",
            "   Precision: 0.948\n",
            "   Recall: 0.947\n"
          ]
        }
      ],
      "source": [
        "# 3.2 ¬∑ Train YOLO model\n",
        "import shutil\n",
        "\n",
        "if dataset_exists:\n",
        "    print(\"\\nüöÄ Starting model training...\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = YOLO(TRAIN_CONFIG[\"model\"])\n",
        "\n",
        "    # Train model\n",
        "    results = model.train(**TRAIN_CONFIG)\n",
        "\n",
        "    # Fix: Construct the save directory path manually from training config\n",
        "    # This is more robust than accessing internal trainer attributes\n",
        "    save_dir = Path(TRAIN_CONFIG[\"project\"]) / TRAIN_CONFIG[\"name\"]\n",
        "    best_model_path = save_dir / \"weights\" / \"best.pt\"\n",
        "\n",
        "    # Alternative fix: Access save_dir from the model's trainer\n",
        "    # best_model_path = Path(model.trainer.save_dir) / \"weights\" / \"best.pt\"\n",
        "\n",
        "    print(f\"\\n‚úÖ Training completed!\")\n",
        "    print(f\"   Best model saved at: {best_model_path}\")\n",
        "\n",
        "    # Verify the file exists before copying\n",
        "    if best_model_path.exists():\n",
        "        # Copy best model to a fixed location\n",
        "        final_model_path = DIRS[\"models\"] / \"waste_detector_best.pt\"\n",
        "        shutil.copy2(best_model_path, final_model_path)\n",
        "        print(f\"   Copied to: {final_model_path}\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è Warning: Best model file not found at {best_model_path}\")\n",
        "        # Try alternative path\n",
        "        last_model_path = save_dir / \"weights\" / \"last.pt\"\n",
        "        if last_model_path.exists():\n",
        "            final_model_path = DIRS[\"models\"] / \"waste_detector_last.pt\"\n",
        "            shutil.copy2(last_model_path, final_model_path)\n",
        "            print(f\"   Using last model instead: {final_model_path}\")\n",
        "\n",
        "    # Optional: Print training metrics\n",
        "    if hasattr(results, 'box'):\n",
        "        print(f\"\\nüìä Training Results:\")\n",
        "        print(f\"   mAP50: {results.box.map50:.3f}\")\n",
        "        print(f\"   mAP50-95: {results.box.map:.3f}\")\n",
        "        print(f\"   Precision: {results.box.mp:.3f}\")\n",
        "        print(f\"   Recall: {results.box.mr:.3f}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Cannot train model - YOLO dataset not found!\")\n",
        "    print(\"Please complete the annotation step first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duBK0oeuDUzy"
      },
      "source": [
        "## **4. Model Evaluation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcbjplxmDUzz"
      },
      "source": [
        "### **4.1 Evaluate Model Performance**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9p7zAvVXDUzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Evaluating model performance...\n",
            "Ultralytics 8.3.158  Python-3.12.7 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
            "Model summary (fused): 72 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2150.4377.2 MB/s, size: 2405.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\labels\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:05<00:00,  4.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         94        105      0.957      0.955      0.973      0.773\n",
            "               Biomll         21         24       0.96          1      0.992      0.748\n",
            "                  Glas         12         12          1          1      0.995      0.826\n",
            "                Papier         26         27       0.96      0.878      0.937      0.719\n",
            "              Restmll         40         42      0.908      0.942      0.969      0.799\n",
            "Speed: 1.6ms preprocess, 18.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
            "\n",
            "üìà Model Performance Metrics:\n",
            "   mAP50: 0.973\n",
            "   mAP50-95: 0.773\n",
            "   Precision: 0.957\n",
            "   Recall: 0.955\n",
            "\n",
            "üìä Per-Class Performance:\n",
            "   Biom√ºll:\n",
            "      AP50: 0.992\n",
            "      AP: 0.748\n",
            "   Glas:\n",
            "      AP50: 0.995\n",
            "      AP: 0.826\n",
            "   Papier:\n",
            "      AP50: 0.937\n",
            "      AP: 0.719\n",
            "   Restm√ºll:\n",
            "      AP50: 0.969\n",
            "      AP: 0.799\n"
          ]
        }
      ],
      "source": [
        "# 4.1 ¬∑ Evaluate the trained model\n",
        "if dataset_exists and 'final_model_path' in locals():\n",
        "    print(\"\\nüìä Evaluating model performance...\")\n",
        "\n",
        "    # Load best model\n",
        "    model = YOLO(final_model_path)\n",
        "\n",
        "    # Run validation\n",
        "    metrics = model.val(\n",
        "        data=TRAIN_CONFIG[\"data\"],\n",
        "        imgsz=TRAIN_CONFIG[\"imgsz\"],\n",
        "        batch=TRAIN_CONFIG[\"batch\"],\n",
        "        conf=0.25,\n",
        "        iou=0.6,\n",
        "        device=TRAIN_CONFIG[\"device\"]\n",
        "    )\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"\\nüìà Model Performance Metrics:\")\n",
        "    print(f\"   mAP50: {metrics.box.map50:.3f}\")\n",
        "    print(f\"   mAP50-95: {metrics.box.map:.3f}\")\n",
        "    print(f\"   Precision: {metrics.box.mp:.3f}\")\n",
        "    print(f\"   Recall: {metrics.box.mr:.3f}\")\n",
        "\n",
        "    # Class-wise performance\n",
        "    print(\"\\nüìä Per-Class Performance:\")\n",
        "    class_names = model.names\n",
        "    for i, class_name in class_names.items():\n",
        "        print(f\"   {class_name}:\")\n",
        "        print(f\"      AP50: {metrics.box.ap50[i]:.3f}\")\n",
        "        print(f\"      AP: {metrics.box.ap[i]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7TSQ4iUDUzz"
      },
      "source": [
        "### **4.2 Visualize Results**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mzrEDXMUDUzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\0a211394-Restm_C3_BCll_af4fdf3d.jpg: 960x960 1 Restmll, 11.5ms\n",
            "Speed: 7.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 960)\n",
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\4a3978dc-Papier_605a661d.jpg: 960x960 2 Papiers, 20.9ms\n",
            "Speed: 6.2ms preprocess, 20.9ms inference, 1.7ms postprocess per image at shape (1, 3, 960, 960)\n",
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\93ff1124-Biom_C3_BCll_ba33ed26.jpg: 960x960 2 Biomlls, 21.6ms\n",
            "Speed: 6.2ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 960, 960)\n",
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\3195e809-Restm_C3_BCll_a9281347.jpg: 960x960 1 Restmll, 21.6ms\n",
            "Speed: 6.4ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 960, 960)\n",
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\2db606f4-Papier_12ff749e.jpg: 960x960 1 Papier, 22.7ms\n",
            "Speed: 6.7ms preprocess, 22.7ms inference, 1.3ms postprocess per image at shape (1, 3, 960, 960)\n",
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\984a5903-Restm_C3_BCll_20c2fcae.jpg: 960x960 1 Restmll, 23.6ms\n",
            "Speed: 6.8ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 960, 960)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Visualization saved to: cv_garbage\\results\\validation_predictions.png\n"
          ]
        }
      ],
      "source": [
        "# 4.2 ¬∑ Visualize predictions on validation set\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "def visualize_predictions(model_path, data_yaml_path, num_samples=6):\n",
        "    \"\"\"Visualize model predictions on validation images\"\"\"\n",
        "\n",
        "    # Load model and data config\n",
        "    model = YOLO(model_path)\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    # Get validation images\n",
        "    val_images_dir = Path(data_yaml_path).parent / data_config['val']\n",
        "    val_images = list(val_images_dir.glob(\"*.jpg\")) + list(val_images_dir.glob(\"*.png\"))\n",
        "\n",
        "    if not val_images:\n",
        "        print(\"No validation images found!\")\n",
        "        return\n",
        "\n",
        "    # Sample random images\n",
        "    sample_images = np.random.choice(val_images, min(num_samples, len(val_images)), replace=False)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    colors = {\n",
        "        0: '#FF6B6B',  # Biom√ºll - Red\n",
        "        1: '#4ECDC4',  # Glas - Turquoise\n",
        "        2: '#45B7D1',  # Papier - Blue\n",
        "        3: '#96CEB4'   # Restm√ºll - Green\n",
        "    }\n",
        "\n",
        "    for idx, (ax, img_path) in enumerate(zip(axes, sample_images)):\n",
        "        # Read image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(img_path, conf=0.25, iou=0.45)\n",
        "\n",
        "        # Display image\n",
        "        ax.imshow(img_rgb)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Draw predictions\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    # Get box coordinates\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                    cls = int(box.cls[0])\n",
        "                    conf = float(box.conf[0])\n",
        "\n",
        "                    # Draw rectangle\n",
        "                    rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                   linewidth=2, edgecolor=colors.get(cls, 'white'),\n",
        "                                   facecolor='none')\n",
        "                    ax.add_patch(rect)\n",
        "\n",
        "                    # Add label\n",
        "                    label = f\"{model.names[cls]} {conf:.2f}\"\n",
        "                    ax.text(x1, y1-5, label, color=colors.get(cls, 'white'),\n",
        "                           fontsize=10, weight='bold',\n",
        "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='black', alpha=0.7))\n",
        "\n",
        "        ax.set_title(f\"Image {idx+1}\")\n",
        "\n",
        "    plt.suptitle(\"Model Predictions on Validation Set\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    output_path = DIRS[\"results\"] / \"validation_predictions.png\"\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"‚úÖ Visualization saved to: {output_path}\")\n",
        "\n",
        "# Run visualization\n",
        "if 'final_model_path' in locals():\n",
        "    visualize_predictions(\n",
        "        final_model_path,\n",
        "        DIRS[\"yolo_dataset\"] / \"data.yaml\",\n",
        "        num_samples=6\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvWyV5UlDUzz"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XmvwH-wDUzz"
      },
      "source": [
        "## **5. Model Deployment**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rypoixjNDUzz"
      },
      "source": [
        "### **5.1 Real-time Inference**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3jW71Pg6DUzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Running inference on sample image...\n",
            "\n",
            "image 1/1 d:\\THD\\CV.v\\Painfully-Trivial\\cv_garbage\\YOLO_Dataset\\images\\val\\066430cd-Restm_C3_BCll_3b52309c.jpg: 960x960 1 Restmll, 19.5ms\n",
            "Speed: 8.6ms preprocess, 19.5ms inference, 2.9ms postprocess per image at shape (1, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
            "1 label saved to runs\\detect\\predict\\labels\n",
            "\n",
            "üóëÔ∏è  Detected: Restm√ºll (confidence: 0.81)\n",
            "   Suitable waste: Cigarette butts, Diapers, Vacuum cleaner bags...\n"
          ]
        }
      ],
      "source": [
        "# 5.1 ¬∑ Real-time inference function\n",
        "def run_inference(model_path, source, conf_threshold=0.25, iou_threshold=0.45):\n",
        "    \"\"\"Run inference on image, video, or webcam\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Define waste disposal rules\n",
        "    waste_rules = {\n",
        "        \"Biom√ºll\": [\n",
        "            \"Food scraps\", \"Vegetable peels\", \"Coffee grounds\",\n",
        "            \"Tea bags\", \"Eggshells\", \"Garden waste\"\n",
        "        ],\n",
        "        \"Glas\": [\n",
        "            \"Glass bottles\", \"Glass jars (empty and clean)\",\n",
        "            \"Window glass\", \"Drinking glasses\"\n",
        "        ],\n",
        "        \"Papier\": [\n",
        "            \"Newspapers\", \"Magazines\", \"Cardboard boxes\",\n",
        "            \"Paper bags\", \"Office paper\", \"Books\"\n",
        "        ],\n",
        "        \"Restm√ºll\": [\n",
        "            \"Cigarette butts\", \"Diapers\", \"Vacuum cleaner bags\",\n",
        "            \"Broken ceramics\", \"Used tissues\", \"Plastic wrap\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Run inference\n",
        "    results = model.predict(\n",
        "        source=source,\n",
        "        conf=conf_threshold,\n",
        "        iou=iou_threshold,\n",
        "        save=True,\n",
        "        save_dir=DIRS[\"results\"],\n",
        "        save_txt=True,\n",
        "        save_conf=True,\n",
        "        stream=True if source == 0 else False  # Stream for webcam\n",
        "    )\n",
        "\n",
        "    # Process results\n",
        "    for r in results:\n",
        "        if r.boxes is not None:\n",
        "            for box in r.boxes:\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                bin_type = model.names[cls]\n",
        "\n",
        "                print(f\"\\nüóëÔ∏è  Detected: {bin_type} (confidence: {conf:.2f})\")\n",
        "                print(f\"   Suitable waste: {', '.join(waste_rules[bin_type][:3])}...\")\n",
        "\n",
        "# Example usage\n",
        "if 'final_model_path' in locals():\n",
        "    # Test on a sample image\n",
        "    test_images = list((DIRS[\"yolo_dataset\"] / \"images\" / \"val\").glob(\"*.jpg\"))\n",
        "    if test_images:\n",
        "        print(\"\\nüîç Running inference on sample image...\")\n",
        "        run_inference(final_model_path, str(test_images[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPuv3E9gDUzz"
      },
      "source": [
        "### **5.2 Interactive Web Interface**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NPxQzW17DUzz"
      },
      "outputs": [],
      "source": [
        "# 5.2 ¬∑ Create interactive interface (for Colab)\n",
        "if is_colab():\n",
        "    import base64\n",
        "    from IPython.display import HTML, display\n",
        "    from google.colab import files\n",
        "\n",
        "    def create_web_interface(model_path):\n",
        "        \"\"\"Create a simple web interface for image upload and detection\"\"\"\n",
        "\n",
        "        html_content = '''\n",
        "        <div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px;\">\n",
        "            <h3>üóëÔ∏è Deggendorf Waste Bin Detector</h3>\n",
        "            <p>Upload an image of a waste bin to identify its type and see disposal guidelines.</p>\n",
        "\n",
        "            <input type=\"file\" id=\"imageUpload\" accept=\"image/*\"\n",
        "                   style=\"margin: 10px 0; padding: 10px; border: 2px dashed #ccc; border-radius: 5px;\">\n",
        "\n",
        "            <div id=\"results\" style=\"margin-top: 20px;\"></div>\n",
        "        </div>\n",
        "\n",
        "        <script>\n",
        "        document.getElementById('imageUpload').addEventListener('change', function(e) {\n",
        "            const file = e.target.files[0];\n",
        "            if (file) {\n",
        "                const reader = new FileReader();\n",
        "                reader.onload = function(e) {\n",
        "                    // Here you would normally send to backend\n",
        "                    document.getElementById('results').innerHTML =\n",
        "                        '<p style=\"color: green;\">‚úÖ Image uploaded! Processing...</p>' +\n",
        "                        '<img src=\"' + e.target.result + '\" style=\"max-width: 300px; margin-top: 10px;\">';\n",
        "                };\n",
        "                reader.readAsDataURL(file);\n",
        "            }\n",
        "        });\n",
        "        </script>\n",
        "        '''\n",
        "\n",
        "        display(HTML(html_content))\n",
        "        print(\"\\nüí° Note: For full functionality, deploy the model as a web service.\")\n",
        "\n",
        "    if 'final_model_path' in locals():\n",
        "        create_web_interface(final_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaiSWX51DUzz"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
